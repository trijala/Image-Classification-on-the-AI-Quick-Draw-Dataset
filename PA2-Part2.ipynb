{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE474/574 - Programming Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Image Classification\n",
    "\n",
    "Additional library requirement: `Pillow`. See [here](https://anaconda.org/anaconda/pillow) for installation instructions.\n",
    "\n",
    "For this part, we will use `keras` with a `tensorflow` backend, instead of directly using `tensorflow`, as in Part 1. See [here](https://anaconda.org/conda-forge/keras) for installation instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Trijala Reddy\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Trijala Reddy\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Trijala Reddy\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Trijala Reddy\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Trijala Reddy\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Trijala Reddy\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Trijala Reddy\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Trijala Reddy\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Trijala Reddy\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Trijala Reddy\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Trijala Reddy\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Trijala Reddy\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from PIL import Image\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(data,size):\n",
    "    '''\n",
    "    Resize images in a given data matrix (1 per row) to the specified size in the tuple - size.\n",
    "    '''\n",
    "    resized_data = np.empty((data.shape[0],size[0]*size[1]))\n",
    "    print(data.shape)\n",
    "    for i in range(data.shape[0]):\n",
    "        d = (np.array(Image.fromarray(data[i,:].reshape((28,28))).resize(size))).flatten()\n",
    "        resized_data[i,:] = d\n",
    "    return resized_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['apple', 'airplane', 'basketball', 'axe', 'banana', 'horse', 'arm', 'alarm clock', 'ant', 'bed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 784)\n",
      "(25000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Preparing the data set\n",
    "with open('AI_quick_draw.pickle', 'rb') as open_ai_quick:\n",
    "    data_train = pickle.load(open_ai_quick)\n",
    "    label_train1 = pickle.load(open_ai_quick)\n",
    "    data_test = pickle.load(open_ai_quick)\n",
    "    label_test1 = pickle.load(open_ai_quick)\n",
    "data_train = resize_images(data_train,(5,5))\n",
    "data_test = resize_images(data_test,(5,5))\n",
    "\n",
    "n_classes = len(np.unique(label_train1))\n",
    "# convert labels to 0-1 hot encoding\n",
    "label_train = np.zeros((label_train1.shape[0], n_classes))\n",
    "a = np.arange(label_train1.shape[0], dtype=np.int64)\n",
    "b = np.array(label_train1, dtype=np.int64).reshape((label_train1.shape[0],))\n",
    "label_train[a, b] = 1\n",
    "\n",
    "label_test = np.zeros((label_test1.shape[0], n_classes))\n",
    "c = np.arange(label_test1.shape[0], dtype=np.int64)\n",
    "d = np.array(label_test1, dtype=np.int64).reshape((label_test1.shape[0],))\n",
    "label_test[c, d] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAAKuCAYAAACG1lVCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5ikZX0n/O+PGWCG80mOwoxROSgSVJR1lZhoxJhdNSRZ0ZC4kE328sJoDmo0J/CYBDasYvBddw2gCaJG3bxEo4aoKwm8iDIJuusYRUAgwLCcDQIyDPf7R1UnRdPNzMD0U/d0fz7XVddVXc9T9b2r5667v/XU09PVWgsAAPRom2kPAAAA5qOsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VrUZbWqTqyqi6c9jtmq6oNV9c7H+BhvrarzttSYAIZUVd+tqh+f9jhgc5m7w1vUZRUAgK2bsjqPqlo+7TEAMD/rNFsrc3fzbPVltareUlVXVdU/V9XaqjruEfY9s6qur6rvVdWaqjpmYttbq+oTVXVeVX0vyYlV9aWqemdV/X9VdXdVfaqq9qyqD48f46tVtfoR8p43vu+d49wT59nvl6vqO1V1e1X9ZVXtP7HtqVX1N+NtN1fVb89x/22r6iNV9cmq2m7TvnMsdvO9Nqrqv1XVJyb2O62qvlAj21fVH1XVdeP59v6qWjm9Z8Eid2RVfb2q7qqqj1XVimSja2KrqtdW1ZVJrhzP23dX1f8dP87Xq+rw8b7mMwvF3B3QVl9Wk1yV5JgkuyZ5W5Lzqmq/efb9apIjk+yR5PwkH5+ZYGMvT/KJJLsl+fD4tlcm+YUkByR5YpJLk5w7foxvJjl1rqCqOijJZ5P8cZLHjXOvmGO/FyT5gySvSLJfkmuTfHS8beckn0/yuST7J3lSki/Muv/KJP9vkh8keUVr7f55njtLz3yvjTckOaJG53Qfk+Q/JfmPbfS3l09LcnBG8/VJGc37U6YxeJaEVyT5iSRPSHJERgcJ5l0TJ/xUkqOTPCXJsUl+JKN5u1uS45PcNt7PfGahmLtDaq0tqktGhfDl4+snJrn4Efa9I8kPj6+/Ncnfztr+pSS/M/H1GUk+O/H1S5NcMc9j/1aSv5hn2weTvHN8/ewkp09s2ynJ+iSrk7wqyT/M8xhvTfKXSS5K8t4kNe3vvUvfl1mvjWcnuT2jxfRV49sqyfeTPHHiPs9Jcs20x+6y+C5Jvpvk5ye+Pj3J+x9pTRx/3ZK8YGL7C5J8O8m/SbLNxO3ms8uCXMzd4S9b/TkTVfXqJL+RUblLRpNjr3n2fUOSX8roKGVLssusfa+f4243T1y/d46vd5pnaAdmdGRrY/ZP8vczX7TW7q6q2zJ6F7Wxx/g3SbbNqGy0TchiCXmk10Zr7StVdXWSvZP8+Xj745LskGRNVf3LwyRZNtCQWXrWTVy/J6P1cM/MvyZ+d3zz9RPbv1hVZyV5X5KDquovkrwxyYqYzywcc3dAW/VpAFW1KskHkvxKkj1ba7sl+T8Z/aPO3veYJG/O6PD87uN975q175YsfNdndNrAxtyYZNXEOHfMaMLfsAmPcWFGHzl8oar2efRDZbHZ2Gujql6bZPuM5t9vju92a0ZvwJ7aWtttfNm1tTbfGzJYCI+0Js54yFrdWntva+2ZSZ6a0Uenb4r5zPDM3QWyVZfVJDtm9A9/S5JU1UlJDp9n352TPDDed3lVnZLRkdWF8uEkP15Vr6iq5TX6xawj59jv/CQnVdWRVbV9kt9Pcllr7btJPp1k36r6tfHJ1jtX1dGTd26tnT5+jC9U1ZxHlFmS5n1tVNXBSd6Z5OczOh/7N6vqyNbagxkV3HdX1d7jfQ+oqhdPYfwsXY+0Jj5MVT2rqo6uqm0z+uj0viQbzGemwNxdIFt1WW2trc3oPNJLM/p4/mlJLpln97/O6Beevp3ReXr3Ze6P/bfU2K5L8pMZ/TLL7RmdL/jDc+z3hSS/l+STSW7K6EjqK8fb/jnJizI6N3ZdkiuT/Ngcj/GOjH7J6vNVtccCPB22Mht5bZyX5LTW2tdaa1cm+e0kfzZeXN+c5DtJvlyj/xXj80kOGXr8LF2PtCbOY5eMfrDfkdHafluSPxpvM58ZjLm7cMqpjgAA9GqrPrIKAMDipqwCANAtZRUAgG4pqwAAdEtZBQCgW5v1F6z22muvtnr16gUaysOtW7du4zttYStWrBg077777hs0L0l23XXXQfPWrl17a2vtcYOGTth9993bfvvtN1jeLbfcMljWjNtvv33QvKc+9amD5iXJdtttN2jemjVrpjpvk+HX3AceeGCwrBnLlg37R3km/iLQorUU5y6Lw3xzd7PK6urVq3P55ZdvuVFtxGmnnTZY1oxDDhn2vzH71re+NWhekvz7f//vB807/PDDrx00cJb99tsv559//mB5Z5111mBZMz72sY8NmvfpT3960LwkOeiggwbNq6qpzttk+DV36Dc9SbLzzjsPmrftttsOmjcNS3HubtiwYbCsGUO/0VoK5pu7TgMAAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1aPu0BPJJ777138Mzjjjtu0Lwf/dEfHTQvSX7u535u8Mxpuuqqq/LTP/3Tg+Udf/zxg2XNOOaYYwbNO/PMMwfNS5Izzjhj8Mxpu/3223P++ecPlnfCCScMljXj4IMPHjRv7dq1g+YlybJlywbPnLYbb7wxp5566mB5H/zgBwfLmnHZZZcNmrdy5cpB85Jkxx13HDxzLo6sAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvLN2fne++9N1/72tcWaiwPc+ihhw6WNeN3fud3Bs178pOfPGhekqxbt27wzGl6whOekLPPPnuwvM997nODZc14znOeM2je6aefPmhekpxxxhmDZ07bypUrc/jhhw+WN/T6lyRr1qwZNG+nnXYaNC9JPvOZzwyeOW3Lli3LzjvvPFjefvvtN1jWjKOOOmrQvBtuuGHQvCR529veNnjmXBxZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOjW8s3ZecOGDfn+97+/UGN5mPXr1w+WNeOAAw4YNO+LX/zioHlJ8vKXv3zwzGnaaaed8tznPnewvCGzpuWUU04ZPPP0008fPHPaVq5cmSOOOGKwvHPOOWewrBl77LHHoHlDr/FJcu+99w6eOW377LNP3vjGNw6Wd/XVVw+WNWPdunWD5r3oRS8aNC9JTjjhhEHzTj311Dlvd2QVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3Vq+OTvvtNNOOfrooxdqLA9z4YUXDpY147nPfe6geatWrRo0L0l22223wTNZXD7/+c8PnnnssccOnrnUnH766YNnbrfddoNnsvi8733vGzyztTZo3oMPPjhoXpIsX75ZNXHBOLIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0K1qrW36zlW3JLl24YbDIrWqtfa4aYWbtzxKU523ibnLo2busrWac+5uVlkFAIAhOQ0AAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1ldYFW1uqpaVS2f9lgAgEevqk6oqgsfw/1PrKqLt+SYlgJlFQBgE7TWPtxaO3ba41hqlFUAtjo+raI35uTCUVYnVNVbquqqqvrnqlpbVceNbz+xqi6pqj+uqruq6h+r6oUT9/tSVf1BVX1lvP2Cqtpjnoxdq+rsqrqpqm6oqndW1bKhniNLxyPM5/9WVZ+Y2O+0qvpCjWxfVX9UVddV1c1V9f6qWjm9Z8FSswnr8Lur6vYkb62qD1bV/1NVn62qu8fb962q91TVHeO1+ulTfkpshTYyDy+e2K9V1Wur6sokV07c9vqqurqqbq2q/1JVc/atqjqzqq6vqu9V1ZqqOmZi21ur6s+r6k/H4/hGVR01sX3/qvpkVd1SVddU1esX7BsyZcrqQ12V5JgkuyZ5W5Lzqmq/8bajk1ydZK8kpyb5n7MK6auT/GKS/ZM8kOS982R8aLz9SUmenuTYJL+0ZZ8GJJl/Pr8hyRHjRfeYJP8pyX9srbUkpyU5OMmRGc3RA5KcMo3Bs2Rtyjq8d5J3jW97RZLfzWht/kGSS5P8/fjrTyT5r4ONnMXkkebhbD+V0dx8ysRtxyU5Kskzkrw8o34wl69mtN7ukeT8JB+vqhUT21+W5KNJdkvyl0nOSpJx+f1Ukq9ltE6/MMmvVdWLN+tZbi1aay7zXJJckdEkOzHJjUlqYttXkvzC+PqXkvzhxLanJLk/ybIkq5O0JMuT7JPRYrpyYt9XJflf036uLov/MjOfx9efneT2JNcmedX4tkry/SRPnLjPc5JcM+2xuyzdy6x1+LpZ2z6Y5AMTX78uyTcnvn5akjun/Rxctv7LrHl48cTtLckLZu3bkvzExNcnJ/nC+PpD7j9Hzh1Jfnh8/a1JPj+x7SlJ7h1fP3qO18NvJTl32t+rhbg4v2JCVb06yW9kVDCTZKeM3p1vSHJDG8+GsWszOoo64/pZ27Yd33fSqvHtN1XVzG3bzLovbBGPMJ/TWvtKVc0cofrz8fbHJdkhyZqJ+VkZvemCQWxkHZ5rrbx54vq9c3y905YfJYvdRubhbHPNy9mdYP859klVvSGjT1f3z6jk7pKHdod1E9fvSbJifG7sqiT7V9WdE9uXJfm7uZ/R1k1ZHauqVUk+kNGh9Etbaxuq6oqMflgnyQFVVROF9aCMDsnPOHDi+kFJ1ie5ddbt12d0ZHWv1toDC/A0IMnG53NVvTbJ9hl9YvCbSf4go/l6b5KnttZumMrAWdI2YR1u894ZtpBNmIezzTUvD0zyjfH1gzJaa2fnHJPkzeOcb7TWHqyqOx4hZ9L1GX3q9eRN2Her55zVf7VjRhPuliSpqpOSHD6xfe8kr6+qbavqPyQ5LMlnJrb/fFU9pap2SPL2JJ9orT3kHVhr7aYkFyY5o6p2qaptquqJVfX8hXtaLFHzzueqOjjJO5P8fJJfSPKbVXVka+3BjBbod1fV3uN9D1i050DRo42twzCELTEP31RVu1fVgUl+NcnH5thn54x+h+WWJMur6pSMjqxuiq8k+V5VvbmqVlbVsqo6vKqetZnj3Cooq2OttbVJzsjo5PybMzrX6ZKJXS5L8uSMjj69K8nPttZum9j+ZxmdP7UuyYok8/1W3quTbJdkbUbnpnwiyXwnbcOjspH5fF6S01prX2utXZnkt5P8WVVtn9G7/O8k+XJVfS/J55McMvT4WZo2YR2GBbeF5uEFSdZkdK7rXyU5e459/jrJZ5N8O6NTBe7LJp4WOD4Y9tKMfjnrmoy6yZ9k9Athi0499DRM5lJVJyb5pdba8+bZ/qUk57XW/mTIcQEAfamqluTJrbXvTHssi4UjqwAAdEtZBQCgW04DAACgW46sAgDQLWUVAIBubdYfBdhrr73a6tWrF2gofVi/fv2izkuSHXbYYdC8NWvW3Npae9ygoROGnrfTOLXmuuuuGzRvr71m/3G2hbfNNsO+t167du1U522yNNZctrxpr7nJ0pi7991336B5K1asGDRvGuabu5tVVlevXp3LL798y42qQzfcMOwf7rnpppsGzUuSo446atC8qrp20MBZhp63999//2BZM04++eRB8/7zf/7Pg+Ylyfbbbz9o3pFHHjnVeZssjTWXLW/aa24y/NzdsGGuv4K6sK688spB8w499NBB86ZhvrnrNAAAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0K3lm7PzPffckyuuuGKhxvIwf/EXfzFY1oy3v/3tg+adccYZg+YlyZOf/OTBM5eST37yk4Nnnn322YPmbbfddoPmTStz2tauXZsjjzxysLx3vOMdg2XNOOaYYwbNW7t27aB5SfL0pz998Myl5qKLLho884UvfOGgeddee+2geUmyxx57DJ45F0dWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0K3lm7PzunXrctpppy3UWB7mD//wDwfLmnHYYYcNmrd69epB85Lk13/91wfPnLYNGzYMlnXllVcOljXjhBNOGDTv4IMPHjQvSU4++eRB884888xB8+Zy//3359prrx0s72Uve9lgWTMOOOCAQfOWL9+sH3tbxK/+6q8Onjlt3/72t/OCF7xgsLyLLrposKwZF1xwwaB5hxxyyKB5SXLfffcNnjkXR1YBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAurV8c3beZpttsv322y/UWB7mtttuGyxrxnHHHTdo3vr16wfNS5J777138Mxpuvvuu3PppZcOlvfc5z53sKwZp5xyyuCZLLynPe1pueiiiwbL+73f+73BsmY873nPGzTv6KOPHjQvSfbdd99B837jN35j0Ly5HHjggXnPe94zWN4FF1wwWNaM448/ftC83/3d3x00L0lOOumkQfMOOOCAOW93ZBUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdWr45O69atSrvf//7F2osD3POOecMljXj3HPPHTRvw4YNg+Ylycknnzxo3kc/+tFB82Zbv359br755sHyXvKSlwyWxeK2bNmy7LLLLoPlnXnmmYNlsbitXLkyRxxxxGB5Q2bNeOUrXzlo3hOe8IRB85Jk+fLNqokLxpFVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG5Va23Td666Jcm1CzccFqlVrbXHTSvcvOVRmuq8TcxdHjVzl63VnHN3s8oqAAAMyWkAAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBeNSq6rtV9eNb8PFOrKqLt9BjfbCq3vko7/vWqjpvfH11VbWqWr4lxsXWq6pOqKoLH8P9t9j8XkqU1QVUVV+qql+a9jhgc5m7bG2UAIbQWvtwa+3YaY9jqVFWAQAeI0feF46yugmq6i1VdVVV/XNVra2q48a3n1hVF1fVH1XVHVV1TVW9ZLztXUmOSXJWVd1dVWdN8zmwNJm7DORZ4/l1R1WdW1Urqmr3qvp0Vd0yvv3TVfX4mTuM5+DV47l5TVWdMNcDV9V/Gc/VXceXs6vqpqq6oareWVXLquqwJO9P8pzxnL1z4iH2qqq/GedcVFWrJh77zKq6vqq+V1VrquqYBfsOsVXZ2No5sV+rqtdW1ZVJrpy47fXj+X3reA7P2bceaQ6OT0X586r60/E4vlFVR01s37+qPjl+jV1TVa9fsG/IlCmrm+aqjH5475rkbUnOq6r9xtuOTvKtJHslOT3J2VVVrbXfSfJ3SX6ltbZTa+1XpjBuMHcZwglJXpzkiUkOTvK7Gf18OTfJqiQHJbk3yVlJUlU7Jnlvkpe01nZO8m+TXDH5gFW1TVV9IMkRSY5trd2V5ENJHkjypCRPT3Jskl9qrX0zyWuSXDqes7vNGts7MprnVyT58MS2ryY5MskeSc5P8vGqWrElviFs9R5p7ZztpzJaT58ycdtxSY5K8owkL0/yi/Pcd2Nz8GVJPppktyR/mX99DW2T5FNJvpbkgCQvTPJrVfXizXqWWwlldRO01j7eWruxtfZga+1jGb17evZ487WttQ+01jZktJDul2SfaY0VJpm7DOSs1tr1rbXbk7wryataa7e11j7ZWruntfbP49ufP3GfB5McXlUrW2s3tda+MbFt2yQfyegH+Etba/dU1T5JXpLk11pr32+t/d8k707yyo2M7a9aa3/bWvtBkt/J6OjrgUnSWjtvPM4HWmtnJNk+ySGP+bvBVm8ja+dsf9Bau721du/EbaeNb7suyXuSvGqenI3NwYtba58Zr9N/luSHx7c/K8njWmtvb63d31q7OskHsvHXw1ZJWd0EVfXqqrqiqu4cf7x0eEbv0pNk3cx+rbV7xld3GnqMMBdzl4FcP3H92iT7V9UOVfXfq+raqvpekr9NsltVLWutfT/J8RkdDb2pqv6qqg6deIwnZXQ06m2ttfvHt63KqMTeNDGf/3uSvTd1bK21u5PcnmT/JKmqN1TVN6vqrvHj7Zp/fX2whG1k7Zzt+o3cdm3Gc26OnI3NwXUT1+9JsqJG58auyuh1dufEGH87i/SAg7K6EePzmz6Q5FeS7Dn+eOn/JKlNuHtbyLHBIzF3GdCBE9cPSnJjkjdkdITo6NbaLkl+ZLy9kqS19tettRdldET/HzOaqzO+meSkJJ+tqpmjTNcn+UGSvVpru40vu7TWnjrePt+c/ZexVdVOGR2tvXF8buCbk7wiye7j18dd2bTXB4vYo1g755p7c70mZuc8ljl4fZJrJl4Lu7XWdm6t/eQm3Hero6xu3I4ZTcRbkqSqTsroHdamuDnJDy3QuGBjzF2G8tqqenxV7ZHR0Z2PJdk5o/NU7xzffurMzlW1T1W9bHzu6g+S3J1kw+QDttY+Mn6sz1fVE1trNyW5MMkZVbXL+JzWJ1bVzKkFNyd5fFVtN2tsP1lVzxvf/o4kl7XWrh+P74GMXh/Lq+qUJLtswe8JW6/HsnbOeFONfsnwwCS/mtFrYrbHMge/kuR7VfXmqlo5/kXDw6vqWZs5zq2CsroRrbW1Sc5IcmlGi+HTklyyiXc/M8nP1ug3Yd+7QEOEOZm7DOj8jIrk1ePLOzM6T29lkluTfDnJ5yb23yajI683ZvSx/POTnDz7QVtrH0ry9iRfrKrVSV6dZLska5PckeQTGR2ZTZIvJvlGknVVdeussZ06znlmRr9wlSR/neSzSb6d0ce092Xuj3NZYh7j2jnjgiRrMvqlvr9KcvYc+zzqOTg+h/WlGf1y1jUZvc7+JKPTCBadas2nfQAAW0JVtSRPbq19Z9pjWSwcWQUAoFvKKgAA3XIaAAAA3XJkFQCAbi3fnJ332muvtnr16gUaysNN46jv+vXrB83bbrvZ/8vK4rNmzZpbW2uPm1b+0PN2KZjGa3PozH/4h3+Y6rxNhp+7d91112BZM2699daN77QF7bbbbhvfaQvbY489Bs37+7//+yU3d6dh6DWpavH/F8Dz9YXNKqurV6/OV77ylS03qo3YsGHDxnfawm688WH/b++CWrVq1aB501BV104zf/Xq1bn88ssHy5tGkXvwwQcHzRv6TV0y/Pd1hx12mOq8TYafu5/61KcGy5rxoQ99aNC8l770pYPmJcnP/dzPDZq33XbbLbm5Ow333XffoHkrVqwYNG8a5usLTgMAAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1avjk733XXXfnMZz6zUGN5mGXLlg2WNWPfffcdNG/vvfceNC9Jtt9++8Ezp+nuu+/OJZdcMljeOeecM1jWjCuvvHLQvNWrVw+aNwT4B8sAABNkSURBVK3MaRt6zb344osHy5rxoz/6o4PmXXjhhYPmJck//dM/DZ45bQ8++GDuueeewfKGXgOT5Kd/+qcHzTvrrLMGzUuSQw45ZPDMuTiyCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4t35yd77777nz5y19eqLE8zDe/+c3Bsmb87d/+7aB5hxxyyKB5SfKmN71p8Mxp+sEPfpCrr756sLxzzjlnsKwZP/ZjPzZo3s/+7M8OmpckL3rRiwbNe8c73jFo3lzuuOOOfOxjHxss77bbbhssa8bpp58+aN6LX/ziQfOS5M477xw8c9quvvrqHH/88YPlfetb3xosa8bv//7vD5r3mte8ZtC8JHnlK185eOZcHFkFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6Nbyzdp5+fLsueeeCzWWOfOGduuttw6at/feew+alyR/8zd/M3jmNC1fvjy77bbbYHnf/va3B8uasfPOOw+at++++w6at1StWLEihx566GB599xzz2BZM375l3950Lxzzjln0Lwk2X///QfPnLYnPelJueCCCwbLu/nmmwfLmjH0v+tFF100aF6S/MiP/MigeaeffvqctzuyCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG5Va22Td37GM57RLrnkkgUczkOtW7dusKwZ++yzz6B5N91006B5SbJ+/fpB8w477LA1rbWjBg2dcNRRR7XLLrtssLxly5YNlsXCqaqpzttktOZedNFFg+X9j//xPwbLmnH77bcPmrfDDjsMmpckr3vd6wbN23XXXac+d4866qh2+eWXT3MIC+6OO+4YNG/XXXcdNC9Jttlm2GOa8627jqwCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdKtaa5u+c9UtSa5duOGwSK1qrT1uWuHmLY/SVOdtYu7yqJm7bK3mnLubVVYBAGBITgMAAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOjWoiurVfXdqvrxLfh4J1bVxVvosT5YVe98lPd9a1WdN76+uqpaVS3fEuNi61RVJ1TVhY/h/ltsbsPm2tJrNWzt/Gyf36Irq71QBFhorbUPt9aOnfY4AGAhKauwCHlnzlJgnsPSsFjL6rOqam1V3VFV51bViqravao+XVW3jG//dFU9fuYO4yOhV1fVP1fVNVV1wlwPXFX/paourqpdx5ezq+qmqrqhqt5ZVcuq6rAk70/ynKq6u6runHiIvarqb8Y5F1XVqonHPrOqrq+q71XVmqo6ZsG+Q2w1quotVXXVeM6srarjxrc/5Oj9+OOj11bVlUmunLjt9eO5fet4/s75un+k+Tc+DeXPq+pPx+P4RlUdNbF9/6r65Pj1dU1VvX7BviEsJkdW1der6q6q+lhVrUiSqvrlqvpOVd1eVX9ZVfvP3GH2PK+Rd1fV/x0/zter6vDxvttX1R9V1XVVdXNVvb+qVk7pubKIbGRdvqSq/ng8H/+xql44cb8vVdUfVNVXxtsvqKo95smYs2MM9Rx7sljL6glJXpzkiUkOTvK7GT3Xc5OsSnJQknuTnJUkVbVjkvcmeUlrbeck/zbJFZMPWFXbVNUHkhyR5NjW2l1JPpTkgSRPSvL0JMcm+aXW2jeTvCbJpa21nVpru80a2zuS7DXO+PDEtq8mOTLJHknOT/LxmcWbJe2qJMck2TXJ25KcV1X7zbPvTyU5OslTJm47LslRSZ6R5OVJfnGe+25s/r0syUeT7JbkL/Ovr59tknwqydeSHJDkhUl+rapevFnPkqXoFUl+IskTMlpbT6yqFyT5g/G2/ZJcm9G8mzQ5z49N8iMZrfW7JTk+yW3j/U4b335kRuv0AUlOWbinwxLySOvy0Umuzujn/KlJ/uesQvrqjNbh/TPqEO+dJ2POjrFln8ZWorW2qC5JvpvkNRNf/2SSq+bY78gkd4yv75jkziQ/k2TlrP1OTHJZko8l+WSS7ca375PkB5P7J3lVkv81cb+LZz3WB5N8dOLrnZJsSHLgPM/ljiQ/PL7+1iTnja+vTtKSLJ/299tl+EtGb3JePnuOjefEC2bt25L8xMTXJyf5wvj6w+borPvOnn+fn9j2lCT3jq8fneS6Wff9rSTnTvt75dLvZbxW//zE16dn9InU2UlOn7h9pyTrk6wef/2QeZ7kBUm+neTfJNlm4vZK8v0kT5y47TlJrpn2c3dZfJdZ6/KNSWpi21eS/ML4+peS/OHEtqckuT/Jssmf7RvrGEvtsljP97l+4vq1Sfavqh2SvDujd/G7j7ftXFXLWmvfr6rjk7wxydlVdUmSN7TW/nG835OS/HCSZ7fW7h/ftirJtkluqqqZrG1mZT/i2Fprd1fV7Rm9u7q+qt6Q0bum/TOasLtk9M6MJayqXp3kNzJayJLRD++9MnqjM9tc8+9hr4d5cjY2/9ZNXL8nyYoanTO4KqPX2OTpLsuS/N3czwj+xew5tX+SPZP8/cyN43XytoyOin53fPPkOvrFqjoryfuSHFRVf5HRWr4iyQ5J1kys0ZXR3ITHZCPr8g1t3C7HZq+7s9fkbfPwn/WPtmMsSov1NIADJ64flNG7nDckOSTJ0a21XTL62CgZLV5prf11a+1FGX3s9I9JPjDxGN9MclKSz1bVIePbrs/oXc9erbXdxpddWmtPHW+fnKhzjq2qdsroI9cbx+cHvjmjj752b6NTB+6aGR9L0/ic5g8k+ZUke47nxf/J/PNirnk31+thds5jmX/XZ3S0areJy86ttZ/chPvCbDdm9IM6yb+cprVnkhsm9nnIPG+tvbe19swkT83oY/83Jbk1o9O9njoxL3dtre200E+AxW0T1uUDaqJh5uHr7uw1eX1G83XSxjrGkrJYy+prq+rx43NEfjujj/B3zmjhunN8+6kzO1fVPlX1svGi+IMkd2fWUavW2kfGj/X5qnpia+2mJBcmOaOqdhmf0/rEqnr++C43J3l8VW03a2w/WVXPG9/+jiSXtdauH4/vgSS3JFleVadkdGSLpW3HjH4w35IkVXVSksM38zHeVKNfMDwwya9m9HqY7bHMv68k+V5VvbmqVtbolwwPr6pnbeY4IRmdL31SVR1ZVdsn+f2M1snvzrVzVT2rqo6uqm0z+tj/viQbWmsPZlQo3l1Ve4/3PcC51GwBG1uX907y+qratqr+Q5LDknxmYvvPV9VTxp/4vj3JJ1prszvHxjrGkrJYy+r5Gf0jXz2+vDPJe5KszOjdy5eTfG5i/20yOvJ6Y5Lbkzw/o3P7HqK19qGMJtYXq2p1RidJb5dkbUbn930ioyOzSfLFJN9Isq6qJt8xnZ9RUb49yTMz+oWrJPnrJJ/N6NyrazNacJfk4X7+VWttbZIzklya0RugpyW5ZDMf5oIkazI6p+qvMjoncLZHPf/Gi+xLMzoP/JqMXmN/ktEvHsBmaa19IcnvZfQ7Ajdl9Iuyr3yEu+ySUSm9I6O5e1uSPxpve3OS7yT5clV9L8nnM/qEDR61TViXL0vy5IzWwncl+dnW2m0T2/8so99hWZfR6Srz/e8pj9QxlpR66GkVwGJSVS3Jk1tr35n2WAAWu6o6MaP/Feh582z/Uka/LP0nQ45ra7dYj6wCALAIKKsAAHTLaQAAAHTLkVUAALq1WX8UYK+99mqrV69eoKE83IYNc/2f5wvr/vvv3/hOW9Dy5cP/XYZtt9120Lw1a9bc2lp73KChE4aet/fee+9gWdOycuXi//Pq0563yWjurlq1auM7biEP/a8h2Vr1MneHXHcfeOCBwbJmfPe73x00b4cddhg0L0n233/OvyGzYOabu5vVlFavXp3LL798y41qI+66667BsmZcd911g+btueeeg+Ylw0++qrp20MBZhp633/jGNwbLmjH0G7sjjjhi0LxpmPa8TZJVq1blkks2938qe/RWrFgxWBYLp4e5O/S6e+uts/9P/YV34oknDpr3jGc8Y9C8JHn7298+aN58c9dpAAAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8s3Z+d77rknV1xxxUKN5WH++I//eLCsGYceeuigeddff/2geUny7/7dvxs8cym55pprBs+86KKLBs174xvfOGhektx3332DZ07bXXfdlc997nOD5T3wwAODZc3YfffdB817/OMfP2hekhxyyCGDZ07b7bffno985COD5V111VWDZc143vOeN2jeb/3Wbw2al/Sz7jqyCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4t35yd/+mf/ilvetObFmosD3PLLbcMljXjnHPOGTTvNa95zaB5SXL22WcPnjlNd9xxRz7+8Y8Plveud71rsKwZJ5xwwqB5++6776B5SXLSSScNnjltu+yyS174whcOlvenf/qng2XNuPnmmwfNO/XUUwfNS5JXvepVg2dO21133ZXPfvazg+VNY+4O7Wd+5meWROZcHFkFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6Nbyzdl57733zmtf+9qFGsvDnH/++YNlzXjGM54xaN5tt902aF6S/Pqv//qgeR//+McHzZtt++23zxOe8ITB8k477bTBsmZ8/etfHzTvfe9736B5SXLyyScPmnfuuecOmjeXbbbZJjvttNNgeV/96lcHy5rxoQ99aNC8r33ta4PmJcnrXve6wTOnbcWKFTn44IMHy7vssssGy5rx7Gc/e9C8xz/+8YPmJcnzn//8QfP+9//+33Pe7sgqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAulWttU3e+aijjmqXX375Ag7noW688cbBsmbcdtttg+b90A/90KB5SbLjjjsOmldVa1prRw0aOmHoeTsNl1566aB5u++++6B5SXLooYcOmjfteZsMP3fvu+++wbJmLFu2bNC8bbfddtC8JHnggQcGzdt2222nPnef+cxntiHXpfe85z2DZc248sorB81bv379oHlJ8pa3vGXQvMMOO2zOuevIKgAA3VJWAQDolrIKAEC3lFUAALqlrAIA0C1lFQCAbimrAAB0S1kFAKBbyioAAN1SVgEA6JayCgBAt5RVAAC6pawCANAtZRUAgG4pqwAAdEtZBQCgW8oqAADdUlYBAOiWsgoAQLeUVQAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3qrW26TtX3ZLk2oUbDovUqtba46YVbt7yKE113ibmLo+aucvWas65u1llFQAAhuQ0AAAAuqWsAgDQLWUVAIBuKasAAHRLWQUAoFvKKgAA3VJWAQDolrIKAEC3lFUAALr1/wMj4/esZsD+TwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x864 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize some images\n",
    "fig = plt.figure(figsize=[12,12])\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4,4,i+1)    \n",
    "    ind = np.random.randint(0,data_train.shape[0])\n",
    "    plt.imshow(data_train[ind,:].reshape((5,5)),cmap='Greys')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    t = plt.title(classes[int(label_train1[ind])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some macosx installations, conflicting copies of mpilib causes trouble with tensorflow.\n",
    "# use the following two lines to resolve that issue\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING**: This cell will take a significantly long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Trijala Reddy\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.8547 - accuracy: 0.6798\n",
      "Epoch 2/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 0.8561 - accuracy: 0.7694\n",
      "Epoch 3/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.8220 - accuracy: 0.7789\n",
      "Epoch 4/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 0.8257 - accuracy: 0.7815\n",
      "Epoch 5/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.8326 - accuracy: 0.7820\n",
      "Epoch 6/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 0.8408 - accuracy: 0.7829 1s - - ETA: 0s - los\n",
      "Epoch 7/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.8431 - accuracy: 0.7824\n",
      "Epoch 8/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.8534 - accuracy: 0.7810\n",
      "Epoch 9/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.8669 - accuracy: 0.7788\n",
      "Epoch 10/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 0.8740 - accuracy: 0.7788\n",
      "Epoch 11/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 0.8792 - accuracy: 0.7793\n",
      "Epoch 12/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 0.8794 - accuracy: 0.7791\n",
      "Epoch 13/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.8842 - accuracy: 0.7764\n",
      "Epoch 14/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 0.8883 - accuracy: 0.7775\n",
      "Epoch 15/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 0.9005 - accuracy: 0.7759\n",
      "Epoch 16/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.8965 - accuracy: 0.7750\n",
      "Epoch 17/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 0.9031 - accuracy: 0.7746\n",
      "Epoch 18/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 0.9058 - accuracy: 0.7740\n",
      "Epoch 19/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 0.9145 - accuracy: 0.7733\n",
      "Epoch 20/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.9211 - accuracy: 0.7730\n",
      "Epoch 21/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.9256 - accuracy: 0.7725\n",
      "Epoch 22/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.9295 - accuracy: 0.7718\n",
      "Epoch 23/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.9414 - accuracy: 0.7693\n",
      "Epoch 24/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 0.9396 - accuracy: 0.7679\n",
      "Epoch 25/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 0.9437 - accuracy: 0.7683\n",
      "Epoch 26/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 0.9406 - accuracy: 0.7676\n",
      "Epoch 27/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.9542 - accuracy: 0.7668\n",
      "Epoch 28/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.9525 - accuracy: 0.7645\n",
      "Epoch 29/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.9649 - accuracy: 0.7627\n",
      "Epoch 30/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 0.9613 - accuracy: 0.7615\n",
      "Epoch 31/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 0.9634 - accuracy: 0.7617\n",
      "Epoch 32/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 0.9694 - accuracy: 0.7620\n",
      "Epoch 33/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 0.9773 - accuracy: 0.7611\n",
      "Epoch 34/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 0.9768 - accuracy: 0.7610\n",
      "Epoch 35/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.9835 - accuracy: 0.7624 0s - loss: 0.9746 - accuracy\n",
      "Epoch 36/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.9736 - accuracy: 0.7603\n",
      "Epoch 37/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.9856 - accuracy: 0.7609\n",
      "Epoch 38/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 0.9775 - accuracy: 0.7612\n",
      "Epoch 39/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.9847 - accuracy: 0.7566\n",
      "Epoch 40/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 0.9848 - accuracy: 0.7587\n",
      "Epoch 41/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 0.9859 - accuracy: 0.7560\n",
      "Epoch 42/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.9869 - accuracy: 0.7574\n",
      "Epoch 43/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 0.9891 - accuracy: 0.7572\n",
      "Epoch 44/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 0.9944 - accuracy: 0.7556\n",
      "Epoch 45/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0021 - accuracy: 0.7571\n",
      "Epoch 46/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 0.9987 - accuracy: 0.7569\n",
      "Epoch 47/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0063 - accuracy: 0.7534\n",
      "Epoch 48/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 0.9959 - accuracy: 0.7535\n",
      "Epoch 49/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0021 - accuracy: 0.7530\n",
      "Epoch 50/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0070 - accuracy: 0.7542\n",
      "Epoch 51/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0032 - accuracy: 0.7530\n",
      "Epoch 52/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 0.9967 - accuracy: 0.7530\n",
      "Epoch 53/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.0155 - accuracy: 0.7528\n",
      "Epoch 54/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0118 - accuracy: 0.7516\n",
      "Epoch 55/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0194 - accuracy: 0.7500\n",
      "Epoch 56/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0170 - accuracy: 0.7508 0s - l\n",
      "Epoch 57/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.0296 - accuracy: 0.7507\n",
      "Epoch 58/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0147 - accuracy: 0.7519\n",
      "Epoch 59/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0304 - accuracy: 0.7510\n",
      "Epoch 60/500\n",
      "100000/100000 [==============================] - 3s 25us/step - loss: 1.0249 - accuracy: 0.7504\n",
      "Epoch 61/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0318 - accuracy: 0.7487\n",
      "Epoch 62/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0283 - accuracy: 0.7488\n",
      "Epoch 63/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0281 - accuracy: 0.7483\n",
      "Epoch 64/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.0320 - accuracy: 0.7465\n",
      "Epoch 65/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0272 - accuracy: 0.7473\n",
      "Epoch 66/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0412 - accuracy: 0.7461\n",
      "Epoch 67/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.0391 - accuracy: 0.7460\n",
      "Epoch 68/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0399 - accuracy: 0.7443\n",
      "Epoch 69/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0454 - accuracy: 0.7450\n",
      "Epoch 70/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0376 - accuracy: 0.7460\n",
      "Epoch 71/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0394 - accuracy: 0.7438\n",
      "Epoch 72/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0374 - accuracy: 0.7448\n",
      "Epoch 73/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0421 - accuracy: 0.7433\n",
      "Epoch 74/500\n",
      "100000/100000 [==============================] - 2s 25us/step - loss: 1.0466 - accuracy: 0.7421\n",
      "Epoch 75/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0499 - accuracy: 0.7422\n",
      "Epoch 76/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0583 - accuracy: 0.7419\n",
      "Epoch 77/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0593 - accuracy: 0.7413\n",
      "Epoch 78/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0523 - accuracy: 0.7403\n",
      "Epoch 79/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.0533 - accuracy: 0.7402\n",
      "Epoch 80/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0575 - accuracy: 0.7383\n",
      "Epoch 81/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0518 - accuracy: 0.7397\n",
      "Epoch 82/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0568 - accuracy: 0.7382\n",
      "Epoch 83/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0699 - accuracy: 0.7376\n",
      "Epoch 84/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0577 - accuracy: 0.7373\n",
      "Epoch 85/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0603 - accuracy: 0.7367\n",
      "Epoch 86/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.0688 - accuracy: 0.7363\n",
      "Epoch 87/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.0724 - accuracy: 0.7367\n",
      "Epoch 88/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0672 - accuracy: 0.7355\n",
      "Epoch 89/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.0736 - accuracy: 0.7330\n",
      "Epoch 90/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.0620 - accuracy: 0.7354\n",
      "Epoch 91/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.0725 - accuracy: 0.7343\n",
      "Epoch 92/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0720 - accuracy: 0.7351\n",
      "Epoch 93/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.0707 - accuracy: 0.7327\n",
      "Epoch 94/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0787 - accuracy: 0.7338 0s - loss: 1.080\n",
      "Epoch 95/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0775 - accuracy: 0.7334\n",
      "Epoch 96/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0795 - accuracy: 0.7326 \n",
      "Epoch 97/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0796 - accuracy: 0.7335\n",
      "Epoch 98/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0653 - accuracy: 0.7321\n",
      "Epoch 99/500\n",
      "100000/100000 [==============================] - ETA: 0s - loss: 1.0853 - accuracy: 0.73 - 2s 22us/step - loss: 1.0827 - accuracy: 0.7321\n",
      "Epoch 100/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.0757 - accuracy: 0.7319\n",
      "Epoch 101/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0717 - accuracy: 0.7316\n",
      "Epoch 102/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.0714 - accuracy: 0.7320\n",
      "Epoch 103/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.0811 - accuracy: 0.7312\n",
      "Epoch 104/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0866 - accuracy: 0.7308\n",
      "Epoch 105/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0749 - accuracy: 0.7310\n",
      "Epoch 106/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0913 - accuracy: 0.7299\n",
      "Epoch 107/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0846 - accuracy: 0.7306\n",
      "Epoch 108/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0782 - accuracy: 0.7296\n",
      "Epoch 109/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0985 - accuracy: 0.7296\n",
      "Epoch 110/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0924 - accuracy: 0.7275\n",
      "Epoch 111/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0841 - accuracy: 0.7270\n",
      "Epoch 112/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0904 - accuracy: 0.7289\n",
      "Epoch 113/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1021 - accuracy: 0.7279\n",
      "Epoch 114/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0872 - accuracy: 0.7285\n",
      "Epoch 115/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0903 - accuracy: 0.7274\n",
      "Epoch 116/500\n",
      "100000/100000 [==============================] - 2s 25us/step - loss: 1.0974 - accuracy: 0.7276\n",
      "Epoch 117/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1000 - accuracy: 0.7280\n",
      "Epoch 118/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1016 - accuracy: 0.7287\n",
      "Epoch 119/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1048 - accuracy: 0.7288\n",
      "Epoch 120/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0942 - accuracy: 0.7280\n",
      "Epoch 121/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0917 - accuracy: 0.7257\n",
      "Epoch 122/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0861 - accuracy: 0.7268\n",
      "Epoch 123/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1015 - accuracy: 0.7277\n",
      "Epoch 124/500\n",
      "100000/100000 [==============================] - 2s 25us/step - loss: 1.1102 - accuracy: 0.7254\n",
      "Epoch 125/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1043 - accuracy: 0.7251\n",
      "Epoch 126/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1144 - accuracy: 0.7263\n",
      "Epoch 127/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1194 - accuracy: 0.7275\n",
      "Epoch 128/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1031 - accuracy: 0.7268\n",
      "Epoch 129/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1039 - accuracy: 0.7257\n",
      "Epoch 130/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1023 - accuracy: 0.7276\n",
      "Epoch 131/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1108 - accuracy: 0.7260\n",
      "Epoch 132/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1103 - accuracy: 0.7250\n",
      "Epoch 133/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1174 - accuracy: 0.7246\n",
      "Epoch 134/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1056 - accuracy: 0.7244\n",
      "Epoch 135/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1262 - accuracy: 0.7256\n",
      "Epoch 136/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1037 - accuracy: 0.7246\n",
      "Epoch 137/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1068 - accuracy: 0.7247\n",
      "Epoch 138/500\n",
      "100000/100000 [==============================] - 2s 25us/step - loss: 1.1237 - accuracy: 0.7229\n",
      "Epoch 139/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1052 - accuracy: 0.7224\n",
      "Epoch 140/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1119 - accuracy: 0.7247\n",
      "Epoch 141/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1089 - accuracy: 0.7235\n",
      "Epoch 142/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1166 - accuracy: 0.7217\n",
      "Epoch 143/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1175 - accuracy: 0.7229\n",
      "Epoch 144/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1136 - accuracy: 0.7216\n",
      "Epoch 145/500\n",
      "100000/100000 [==============================] - 3s 27us/step - loss: 1.1253 - accuracy: 0.7207\n",
      "Epoch 146/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1206 - accuracy: 0.7218\n",
      "Epoch 147/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1321 - accuracy: 0.7222\n",
      "Epoch 148/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1251 - accuracy: 0.7221 0s - loss: 1.1198 \n",
      "Epoch 149/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1166 - accuracy: 0.7214\n",
      "Epoch 150/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1301 - accuracy: 0.7201\n",
      "Epoch 151/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1181 - accuracy: 0.7197\n",
      "Epoch 152/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1297 - accuracy: 0.7210\n",
      "Epoch 153/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1328 - accuracy: 0.7194\n",
      "Epoch 154/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1333 - accuracy: 0.7216\n",
      "Epoch 155/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1239 - accuracy: 0.7210\n",
      "Epoch 156/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1197 - accuracy: 0.7203\n",
      "Epoch 157/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1299 - accuracy: 0.7204\n",
      "Epoch 158/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1285 - accuracy: 0.7194\n",
      "Epoch 159/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1398 - accuracy: 0.7193\n",
      "Epoch 160/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1302 - accuracy: 0.7186\n",
      "Epoch 161/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1361 - accuracy: 0.7203\n",
      "Epoch 162/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1355 - accuracy: 0.7215\n",
      "Epoch 163/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1409 - accuracy: 0.7202\n",
      "Epoch 164/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1351 - accuracy: 0.7210\n",
      "Epoch 165/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1254 - accuracy: 0.7203\n",
      "Epoch 166/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1310 - accuracy: 0.7203\n",
      "Epoch 167/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1313 - accuracy: 0.7199 0s - loss: 1\n",
      "Epoch 168/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1298 - accuracy: 0.7188\n",
      "Epoch 169/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1226 - accuracy: 0.7206\n",
      "Epoch 170/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1258 - accuracy: 0.7209\n",
      "Epoch 171/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1377 - accuracy: 0.7197\n",
      "Epoch 172/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1286 - accuracy: 0.7207 0s - loss: 1.1235 - accuracy\n",
      "Epoch 173/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1178 - accuracy: 0.7212\n",
      "Epoch 174/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1201 - accuracy: 0.7207\n",
      "Epoch 175/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1186 - accuracy: 0.7222\n",
      "Epoch 176/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1216 - accuracy: 0.7207\n",
      "Epoch 177/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1285 - accuracy: 0.7214\n",
      "Epoch 178/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1243 - accuracy: 0.7205\n",
      "Epoch 179/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1268 - accuracy: 0.7208\n",
      "Epoch 180/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1224 - accuracy: 0.7212\n",
      "Epoch 181/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1233 - accuracy: 0.7216\n",
      "Epoch 182/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1347 - accuracy: 0.7223\n",
      "Epoch 183/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1247 - accuracy: 0.7215\n",
      "Epoch 184/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1261 - accuracy: 0.7229\n",
      "Epoch 185/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1238 - accuracy: 0.7209\n",
      "Epoch 186/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1207 - accuracy: 0.7202\n",
      "Epoch 187/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1237 - accuracy: 0.7191\n",
      "Epoch 188/500\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 1.1192 - accuracy: 0.7194\n",
      "Epoch 189/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1269 - accuracy: 0.7198\n",
      "Epoch 190/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1263 - accuracy: 0.7210\n",
      "Epoch 191/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1274 - accuracy: 0.7204\n",
      "Epoch 192/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1268 - accuracy: 0.7206\n",
      "Epoch 193/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1424 - accuracy: 0.7198\n",
      "Epoch 194/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1368 - accuracy: 0.7213\n",
      "Epoch 195/500\n",
      "100000/100000 [==============================] - 2s 25us/step - loss: 1.1308 - accuracy: 0.7234\n",
      "Epoch 196/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1453 - accuracy: 0.7223\n",
      "Epoch 197/500\n",
      "100000/100000 [==============================] - 2s 25us/step - loss: 1.1332 - accuracy: 0.7203\n",
      "Epoch 198/500\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 1.1366 - accuracy: 0.7215\n",
      "Epoch 199/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1422 - accuracy: 0.7206\n",
      "Epoch 200/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1406 - accuracy: 0.7201\n",
      "Epoch 201/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1378 - accuracy: 0.7206\n",
      "Epoch 202/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1389 - accuracy: 0.7212\n",
      "Epoch 203/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1562 - accuracy: 0.7205\n",
      "Epoch 204/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1395 - accuracy: 0.7195\n",
      "Epoch 205/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1458 - accuracy: 0.7201\n",
      "Epoch 206/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1444 - accuracy: 0.7197\n",
      "Epoch 207/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1436 - accuracy: 0.7192\n",
      "Epoch 208/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1479 - accuracy: 0.7185\n",
      "Epoch 209/500\n",
      "100000/100000 [==============================] - 2s 25us/step - loss: 1.1502 - accuracy: 0.7192\n",
      "Epoch 210/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1347 - accuracy: 0.7183\n",
      "Epoch 211/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1298 - accuracy: 0.7190\n",
      "Epoch 212/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1292 - accuracy: 0.7166\n",
      "Epoch 213/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1406 - accuracy: 0.7167\n",
      "Epoch 214/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1291 - accuracy: 0.7171\n",
      "Epoch 215/500\n",
      "100000/100000 [==============================] - 3s 25us/step - loss: 1.1322 - accuracy: 0.7160\n",
      "Epoch 216/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1502 - accuracy: 0.7156\n",
      "Epoch 217/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1441 - accuracy: 0.7166\n",
      "Epoch 218/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1474 - accuracy: 0.7165\n",
      "Epoch 219/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1459 - accuracy: 0.7153\n",
      "Epoch 220/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1420 - accuracy: 0.7154\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1341 - accuracy: 0.7155\n",
      "Epoch 222/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1339 - accuracy: 0.7172 0s - loss: 1.1363 \n",
      "Epoch 223/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1391 - accuracy: 0.7162\n",
      "Epoch 224/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1402 - accuracy: 0.7152\n",
      "Epoch 225/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1405 - accuracy: 0.7143\n",
      "Epoch 226/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1329 - accuracy: 0.7144\n",
      "Epoch 227/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1531 - accuracy: 0.7147\n",
      "Epoch 228/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1504 - accuracy: 0.7152\n",
      "Epoch 229/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1462 - accuracy: 0.7157\n",
      "Epoch 230/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1389 - accuracy: 0.7145\n",
      "Epoch 231/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1465 - accuracy: 0.7146\n",
      "Epoch 232/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1461 - accuracy: 0.7131\n",
      "Epoch 233/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1421 - accuracy: 0.7134\n",
      "Epoch 234/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1470 - accuracy: 0.7140\n",
      "Epoch 235/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1397 - accuracy: 0.7129\n",
      "Epoch 236/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1425 - accuracy: 0.7130\n",
      "Epoch 237/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1477 - accuracy: 0.7142\n",
      "Epoch 238/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1458 - accuracy: 0.7143\n",
      "Epoch 239/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1410 - accuracy: 0.7136\n",
      "Epoch 240/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1326 - accuracy: 0.7144\n",
      "Epoch 241/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1399 - accuracy: 0.7135\n",
      "Epoch 242/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1404 - accuracy: 0.7144\n",
      "Epoch 243/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1356 - accuracy: 0.7143\n",
      "Epoch 244/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1399 - accuracy: 0.7143\n",
      "Epoch 245/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1417 - accuracy: 0.7131\n",
      "Epoch 246/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1404 - accuracy: 0.7124\n",
      "Epoch 247/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1494 - accuracy: 0.7132\n",
      "Epoch 248/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1379 - accuracy: 0.7137\n",
      "Epoch 249/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1286 - accuracy: 0.7135\n",
      "Epoch 250/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1227 - accuracy: 0.7136\n",
      "Epoch 251/500\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 1.1412 - accuracy: 0.7154\n",
      "Epoch 252/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1378 - accuracy: 0.7136\n",
      "Epoch 253/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1335 - accuracy: 0.7130\n",
      "Epoch 254/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1420 - accuracy: 0.7143\n",
      "Epoch 255/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1300 - accuracy: 0.7144\n",
      "Epoch 256/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1425 - accuracy: 0.7161\n",
      "Epoch 257/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1287 - accuracy: 0.7142\n",
      "Epoch 258/500\n",
      "100000/100000 [==============================] - 2s 25us/step - loss: 1.1403 - accuracy: 0.7150\n",
      "Epoch 259/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1374 - accuracy: 0.7146\n",
      "Epoch 260/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1447 - accuracy: 0.7143\n",
      "Epoch 261/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1382 - accuracy: 0.7150\n",
      "Epoch 262/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1426 - accuracy: 0.7153\n",
      "Epoch 263/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1358 - accuracy: 0.7139\n",
      "Epoch 264/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1324 - accuracy: 0.7134\n",
      "Epoch 265/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1298 - accuracy: 0.7137\n",
      "Epoch 266/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1381 - accuracy: 0.7138\n",
      "Epoch 267/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1366 - accuracy: 0.7147\n",
      "Epoch 268/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1350 - accuracy: 0.7128 \n",
      "Epoch 269/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1322 - accuracy: 0.7127\n",
      "Epoch 270/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1309 - accuracy: 0.7132\n",
      "Epoch 271/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1263 - accuracy: 0.7113\n",
      "Epoch 272/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1430 - accuracy: 0.7136\n",
      "Epoch 273/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1255 - accuracy: 0.7118\n",
      "Epoch 274/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1305 - accuracy: 0.7110\n",
      "Epoch 275/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1354 - accuracy: 0.7110\n",
      "Epoch 276/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1361 - accuracy: 0.7125\n",
      "Epoch 277/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1328 - accuracy: 0.7110\n",
      "Epoch 278/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1308 - accuracy: 0.7117\n",
      "Epoch 279/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1212 - accuracy: 0.7115\n",
      "Epoch 280/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1325 - accuracy: 0.7096\n",
      "Epoch 281/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1260 - accuracy: 0.7101\n",
      "Epoch 282/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1373 - accuracy: 0.7103\n",
      "Epoch 283/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1247 - accuracy: 0.7088\n",
      "Epoch 284/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1369 - accuracy: 0.7090\n",
      "Epoch 285/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1238 - accuracy: 0.7075\n",
      "Epoch 286/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1328 - accuracy: 0.7079\n",
      "Epoch 287/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1322 - accuracy: 0.7090\n",
      "Epoch 288/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1285 - accuracy: 0.7078\n",
      "Epoch 289/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1531 - accuracy: 0.7096\n",
      "Epoch 290/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1422 - accuracy: 0.7089\n",
      "Epoch 291/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1315 - accuracy: 0.7099\n",
      "Epoch 292/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1299 - accuracy: 0.7081\n",
      "Epoch 293/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1334 - accuracy: 0.7082\n",
      "Epoch 294/500\n",
      "100000/100000 [==============================] - 2s 25us/step - loss: 1.1378 - accuracy: 0.7074\n",
      "Epoch 295/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1276 - accuracy: 0.7087 0s - loss: 1.1273 - accuracy: \n",
      "Epoch 296/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1293 - accuracy: 0.7074\n",
      "Epoch 297/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1320 - accuracy: 0.7074\n",
      "Epoch 298/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1386 - accuracy: 0.7067\n",
      "Epoch 299/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1370 - accuracy: 0.7069\n",
      "Epoch 300/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1311 - accuracy: 0.7083\n",
      "Epoch 301/500\n",
      "100000/100000 [==============================] - 3s 27us/step - loss: 1.1489 - accuracy: 0.7086\n",
      "Epoch 302/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1293 - accuracy: 0.7084\n",
      "Epoch 303/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1331 - accuracy: 0.7090\n",
      "Epoch 304/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1422 - accuracy: 0.7090\n",
      "Epoch 305/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1319 - accuracy: 0.7085\n",
      "Epoch 306/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1297 - accuracy: 0.7097 0s - loss: 1.1326 - \n",
      "Epoch 307/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1378 - accuracy: 0.7093\n",
      "Epoch 308/500\n",
      "100000/100000 [==============================] - ETA: 0s - loss: 1.1114 - accuracy: 0.71 - 2s 25us/step - loss: 1.1124 - accuracy: 0.7104\n",
      "Epoch 309/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1208 - accuracy: 0.7120\n",
      "Epoch 310/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1216 - accuracy: 0.7097\n",
      "Epoch 311/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1190 - accuracy: 0.7106\n",
      "Epoch 312/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1113 - accuracy: 0.7092\n",
      "Epoch 313/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1165 - accuracy: 0.7118\n",
      "Epoch 314/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1163 - accuracy: 0.7105\n",
      "Epoch 315/500\n",
      "100000/100000 [==============================] - 2s 25us/step - loss: 1.1097 - accuracy: 0.7093\n",
      "Epoch 316/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1118 - accuracy: 0.7084\n",
      "Epoch 317/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1148 - accuracy: 0.7092\n",
      "Epoch 318/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1140 - accuracy: 0.7107\n",
      "Epoch 319/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1173 - accuracy: 0.7113\n",
      "Epoch 320/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1160 - accuracy: 0.7104\n",
      "Epoch 321/500\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 1.1193 - accuracy: 0.7102\n",
      "Epoch 322/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1118 - accuracy: 0.7095\n",
      "Epoch 323/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1110 - accuracy: 0.7117\n",
      "Epoch 324/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1176 - accuracy: 0.7106\n",
      "Epoch 325/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1120 - accuracy: 0.7110\n",
      "Epoch 326/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1272 - accuracy: 0.7089\n",
      "Epoch 327/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1090 - accuracy: 0.7103\n",
      "Epoch 328/500\n",
      "100000/100000 [==============================] - 2s 25us/step - loss: 1.1054 - accuracy: 0.7111\n",
      "Epoch 329/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1218 - accuracy: 0.7098\n",
      "Epoch 330/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1189 - accuracy: 0.7107\n",
      "Epoch 331/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1171 - accuracy: 0.7106\n",
      "Epoch 332/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1166 - accuracy: 0.7087\n",
      "Epoch 333/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1174 - accuracy: 0.7096\n",
      "Epoch 334/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1059 - accuracy: 0.7110\n",
      "Epoch 335/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1234 - accuracy: 0.7099\n",
      "Epoch 336/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1137 - accuracy: 0.7105\n",
      "Epoch 337/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1189 - accuracy: 0.7103\n",
      "Epoch 338/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1154 - accuracy: 0.7104\n",
      "Epoch 339/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1089 - accuracy: 0.7098\n",
      "Epoch 340/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0976 - accuracy: 0.7100\n",
      "Epoch 341/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1026 - accuracy: 0.7098\n",
      "Epoch 342/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1097 - accuracy: 0.7085\n",
      "Epoch 343/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1062 - accuracy: 0.7100\n",
      "Epoch 344/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1160 - accuracy: 0.7099\n",
      "Epoch 345/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1078 - accuracy: 0.7092\n",
      "Epoch 346/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1075 - accuracy: 0.7089\n",
      "Epoch 347/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1093 - accuracy: 0.7097\n",
      "Epoch 348/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1051 - accuracy: 0.7105\n",
      "Epoch 349/500\n",
      "100000/100000 [==============================] - 3s 25us/step - loss: 1.1218 - accuracy: 0.7099\n",
      "Epoch 350/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1092 - accuracy: 0.7103\n",
      "Epoch 351/500\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 1.1108 - accuracy: 0.7089\n",
      "Epoch 352/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1229 - accuracy: 0.7087\n",
      "Epoch 353/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1107 - accuracy: 0.7099\n",
      "Epoch 354/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1062 - accuracy: 0.7085 0s - loss: 1.0927 \n",
      "Epoch 355/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1173 - accuracy: 0.7100\n",
      "Epoch 356/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1088 - accuracy: 0.7100\n",
      "Epoch 357/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1193 - accuracy: 0.7094\n",
      "Epoch 358/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1164 - accuracy: 0.7089\n",
      "Epoch 359/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1108 - accuracy: 0.7102\n",
      "Epoch 360/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1076 - accuracy: 0.7100\n",
      "Epoch 361/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1149 - accuracy: 0.7106\n",
      "Epoch 362/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1253 - accuracy: 0.7104 0s - los\n",
      "Epoch 363/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1202 - accuracy: 0.7085\n",
      "Epoch 364/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1138 - accuracy: 0.7103\n",
      "Epoch 365/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1113 - accuracy: 0.7085\n",
      "Epoch 366/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1161 - accuracy: 0.7092\n",
      "Epoch 367/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1129 - accuracy: 0.7080\n",
      "Epoch 368/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1167 - accuracy: 0.7085\n",
      "Epoch 369/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1222 - accuracy: 0.7103\n",
      "Epoch 370/500\n",
      "100000/100000 [==============================] - 3s 25us/step - loss: 1.1068 - accuracy: 0.7102\n",
      "Epoch 371/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1102 - accuracy: 0.7084\n",
      "Epoch 372/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1094 - accuracy: 0.7097\n",
      "Epoch 373/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1164 - accuracy: 0.7096\n",
      "Epoch 374/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1088 - accuracy: 0.7093\n",
      "Epoch 375/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1160 - accuracy: 0.7099\n",
      "Epoch 376/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1117 - accuracy: 0.7094\n",
      "Epoch 377/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1115 - accuracy: 0.7078\n",
      "Epoch 378/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1105 - accuracy: 0.7091\n",
      "Epoch 379/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1082 - accuracy: 0.7096\n",
      "Epoch 380/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1089 - accuracy: 0.7105\n",
      "Epoch 381/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1118 - accuracy: 0.7096\n",
      "Epoch 382/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1188 - accuracy: 0.7080\n",
      "Epoch 383/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1055 - accuracy: 0.7089\n",
      "Epoch 384/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1211 - accuracy: 0.7094\n",
      "Epoch 385/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1287 - accuracy: 0.7079\n",
      "Epoch 386/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1104 - accuracy: 0.7073\n",
      "Epoch 387/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1164 - accuracy: 0.7101\n",
      "Epoch 388/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1164 - accuracy: 0.7093\n",
      "Epoch 389/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1122 - accuracy: 0.7095\n",
      "Epoch 390/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1123 - accuracy: 0.7094 0s - loss: 1.1024 \n",
      "Epoch 391/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1113 - accuracy: 0.7090\n",
      "Epoch 392/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1065 - accuracy: 0.7085\n",
      "Epoch 393/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1129 - accuracy: 0.7081\n",
      "Epoch 394/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1095 - accuracy: 0.7084\n",
      "Epoch 395/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1134 - accuracy: 0.7083\n",
      "Epoch 396/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1046 - accuracy: 0.7088\n",
      "Epoch 397/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1046 - accuracy: 0.7083\n",
      "Epoch 398/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1079 - accuracy: 0.7073\n",
      "Epoch 399/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1149 - accuracy: 0.7084\n",
      "Epoch 400/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1105 - accuracy: 0.7078\n",
      "Epoch 401/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1122 - accuracy: 0.7096\n",
      "Epoch 402/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1177 - accuracy: 0.7076\n",
      "Epoch 403/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1078 - accuracy: 0.7082\n",
      "Epoch 404/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1180 - accuracy: 0.7067\n",
      "Epoch 405/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1042 - accuracy: 0.7085\n",
      "Epoch 406/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1183 - accuracy: 0.7064\n",
      "Epoch 407/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1043 - accuracy: 0.7072 0s - loss: 1.1045 - accuracy: \n",
      "Epoch 408/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1145 - accuracy: 0.7074\n",
      "Epoch 409/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1121 - accuracy: 0.7073\n",
      "Epoch 410/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1051 - accuracy: 0.7080\n",
      "Epoch 411/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0995 - accuracy: 0.7081\n",
      "Epoch 412/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1002 - accuracy: 0.7064\n",
      "Epoch 413/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1015 - accuracy: 0.7088\n",
      "Epoch 414/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0968 - accuracy: 0.7086\n",
      "Epoch 415/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1029 - accuracy: 0.7073\n",
      "Epoch 416/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1047 - accuracy: 0.7063\n",
      "Epoch 417/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0966 - accuracy: 0.7066\n",
      "Epoch 418/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0982 - accuracy: 0.7054\n",
      "Epoch 419/500\n",
      "100000/100000 [==============================] - 2s 25us/step - loss: 1.1008 - accuracy: 0.7077\n",
      "Epoch 420/500\n",
      "100000/100000 [==============================] - 2s 25us/step - loss: 1.0953 - accuracy: 0.7084\n",
      "Epoch 421/500\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 1.0967 - accuracy: 0.7064\n",
      "Epoch 422/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.0963 - accuracy: 0.7066\n",
      "Epoch 423/500\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 1.1010 - accuracy: 0.7071\n",
      "Epoch 424/500\n",
      "100000/100000 [==============================] - 3s 25us/step - loss: 1.0974 - accuracy: 0.7072\n",
      "Epoch 425/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.0960 - accuracy: 0.7073\n",
      "Epoch 426/500\n",
      "100000/100000 [==============================] - 2s 25us/step - loss: 1.0854 - accuracy: 0.7064\n",
      "Epoch 427/500\n",
      "100000/100000 [==============================] - 3s 27us/step - loss: 1.0920 - accuracy: 0.7077\n",
      "Epoch 428/500\n",
      "100000/100000 [==============================] - 3s 27us/step - loss: 1.0935 - accuracy: 0.7072\n",
      "Epoch 429/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0870 - accuracy: 0.7066\n",
      "Epoch 430/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0902 - accuracy: 0.7077\n",
      "Epoch 431/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0894 - accuracy: 0.7057\n",
      "Epoch 432/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0940 - accuracy: 0.7066\n",
      "Epoch 433/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0879 - accuracy: 0.7070\n",
      "Epoch 434/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0952 - accuracy: 0.7062\n",
      "Epoch 435/500\n",
      "100000/100000 [==============================] - 2s 25us/step - loss: 1.0934 - accuracy: 0.7068\n",
      "Epoch 436/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0963 - accuracy: 0.7055\n",
      "Epoch 437/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0881 - accuracy: 0.7070\n",
      "Epoch 438/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1041 - accuracy: 0.7061\n",
      "Epoch 439/500\n",
      "100000/100000 [==============================] - 3s 25us/step - loss: 1.0999 - accuracy: 0.7075\n",
      "Epoch 440/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.0983 - accuracy: 0.7076\n",
      "Epoch 441/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0983 - accuracy: 0.7053\n",
      "Epoch 442/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0988 - accuracy: 0.7052\n",
      "Epoch 443/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0923 - accuracy: 0.7060\n",
      "Epoch 444/500\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 1.0940 - accuracy: 0.7051\n",
      "Epoch 445/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0899 - accuracy: 0.7054\n",
      "Epoch 446/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.0899 - accuracy: 0.7058\n",
      "Epoch 447/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0851 - accuracy: 0.7059\n",
      "Epoch 448/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0847 - accuracy: 0.7074\n",
      "Epoch 449/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0991 - accuracy: 0.7060\n",
      "Epoch 450/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0936 - accuracy: 0.7058\n",
      "Epoch 451/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0978 - accuracy: 0.7058\n",
      "Epoch 452/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.0984 - accuracy: 0.7052\n",
      "Epoch 453/500\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 1.0954 - accuracy: 0.7059\n",
      "Epoch 454/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1021 - accuracy: 0.7052\n",
      "Epoch 455/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0949 - accuracy: 0.7056\n",
      "Epoch 456/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1021 - accuracy: 0.7055\n",
      "Epoch 457/500\n",
      "100000/100000 [==============================] - 3s 27us/step - loss: 1.0933 - accuracy: 0.7049\n",
      "Epoch 458/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.0960 - accuracy: 0.7047\n",
      "Epoch 459/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.0981 - accuracy: 0.7054\n",
      "Epoch 460/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1015 - accuracy: 0.7046\n",
      "Epoch 461/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1051 - accuracy: 0.7066\n",
      "Epoch 462/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1109 - accuracy: 0.7060\n",
      "Epoch 463/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1072 - accuracy: 0.7061\n",
      "Epoch 464/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1058 - accuracy: 0.7046\n",
      "Epoch 465/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.0978 - accuracy: 0.7060\n",
      "Epoch 466/500\n",
      "100000/100000 [==============================] - 3s 27us/step - loss: 1.1151 - accuracy: 0.7049\n",
      "Epoch 467/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1143 - accuracy: 0.7053\n",
      "Epoch 468/500\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 1.1120 - accuracy: 0.7042\n",
      "Epoch 469/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1120 - accuracy: 0.7062\n",
      "Epoch 470/500\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 1.1012 - accuracy: 0.7047\n",
      "Epoch 471/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1125 - accuracy: 0.7051\n",
      "Epoch 472/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1091 - accuracy: 0.7045\n",
      "Epoch 473/500\n",
      "100000/100000 [==============================] - 3s 27us/step - loss: 1.1125 - accuracy: 0.7051\n",
      "Epoch 474/500\n",
      "100000/100000 [==============================] - 3s 27us/step - loss: 1.1122 - accuracy: 0.7043\n",
      "Epoch 475/500\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 1.1118 - accuracy: 0.7054\n",
      "Epoch 476/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1082 - accuracy: 0.7047\n",
      "Epoch 477/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1060 - accuracy: 0.7052\n",
      "Epoch 478/500\n",
      "100000/100000 [==============================] - 3s 25us/step - loss: 1.1024 - accuracy: 0.7053\n",
      "Epoch 479/500\n",
      "100000/100000 [==============================] - 3s 34us/step - loss: 1.1066 - accuracy: 0.7053\n",
      "Epoch 480/500\n",
      "100000/100000 [==============================] - 3s 28us/step - loss: 1.1138 - accuracy: 0.7040\n",
      "Epoch 481/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1134 - accuracy: 0.7052\n",
      "Epoch 482/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1158 - accuracy: 0.7051\n",
      "Epoch 483/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1060 - accuracy: 0.7053\n",
      "Epoch 484/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1028 - accuracy: 0.7049\n",
      "Epoch 485/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1050 - accuracy: 0.7048\n",
      "Epoch 486/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1005 - accuracy: 0.7044\n",
      "Epoch 487/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1072 - accuracy: 0.7048\n",
      "Epoch 488/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1248 - accuracy: 0.7047\n",
      "Epoch 489/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1224 - accuracy: 0.7044\n",
      "Epoch 490/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1227 - accuracy: 0.7043\n",
      "Epoch 491/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1101 - accuracy: 0.7054\n",
      "Epoch 492/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1128 - accuracy: 0.7050\n",
      "Epoch 493/500\n",
      "100000/100000 [==============================] - 2s 24us/step - loss: 1.1075 - accuracy: 0.7049\n",
      "Epoch 494/500\n",
      "100000/100000 [==============================] - 2s 23us/step - loss: 1.1160 - accuracy: 0.7050\n",
      "Epoch 495/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1129 - accuracy: 0.7051\n",
      "Epoch 496/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1241 - accuracy: 0.7053 0s - loss: 1.113\n",
      "Epoch 497/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1200 - accuracy: 0.7052\n",
      "Epoch 498/500\n",
      "100000/100000 [==============================] - 2s 21us/step - loss: 1.1154 - accuracy: 0.7052\n",
      "Epoch 499/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1175 - accuracy: 0.7056\n",
      "Epoch 500/500\n",
      "100000/100000 [==============================] - 2s 22us/step - loss: 1.1236 - accuracy: 0.7044\n",
      "1142.3268477916718\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "start = time.time()\n",
    "model.add(Dense(256, activation='relu', input_dim=data_train.shape[1]))\n",
    "# you can add more Dense layers here\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# data_train1 = resize_images(data_train,(20,20))\n",
    "# data_test1 = resize_images(data_test,(20,20))\n",
    "# label_train1 = resize_images(label_train,(20,20))\n",
    "model.fit(data_train, label_train, epochs=500, batch_size=32)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.7042\n"
     ]
    }
   ],
   "source": [
    "predict_test = model.predict_classes(data_test)\n",
    "acc_test = np.where(label_test1 == predict_test)[0].shape[0]/data_test.shape[0]\n",
    "print('Testing accuracy {}'.format(acc_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to use with the drawing app (this will be released later)\n",
    "model.save('pa2-part2-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
